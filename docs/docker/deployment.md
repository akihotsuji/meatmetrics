# Docker ç’°å¢ƒãƒ‡ãƒ—ãƒ­ã‚¤ãƒ»é‹ç”¨æ‰‹é † ğŸ“¦

## æ¦‚è¦

MeatMetrics ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã® Docker ç’°å¢ƒã‚’æœ¬ç•ªç’°å¢ƒã«ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã€é‹ç”¨ç®¡ç†ã‚’è¡Œã†ãŸã‚ã®è©³ç´°ãªæ‰‹é †æ›¸ã§ã™ã€‚

## ãƒ‡ãƒ—ãƒ­ã‚¤æˆ¦ç•¥

### 1. ãƒ‡ãƒ—ãƒ­ã‚¤æ–¹å¼

- **Blue-Green Deployment**: ãƒ€ã‚¦ãƒ³ã‚¿ã‚¤ãƒ ãªã—ã§ã®ãƒ‡ãƒ—ãƒ­ã‚¤
- **Rolling Update**: æ®µéšçš„ãªæ›´æ–°ã«ã‚ˆã‚‹ãƒªã‚¹ã‚¯åˆ†æ•£
- **Canary Deployment**: ä¸€éƒ¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®æ®µéšçš„ãƒªãƒªãƒ¼ã‚¹

### 2. ç’°å¢ƒæ§‹æˆ

```
é–‹ç™ºç’°å¢ƒ (Development)
â”œâ”€â”€ ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç’°å¢ƒ
â”œâ”€â”€ é–‹ç™ºã‚µãƒ¼ãƒãƒ¼ç’°å¢ƒ
â””â”€â”€ ã‚¹ãƒ†ãƒ¼ã‚¸ãƒ³ã‚°ç’°å¢ƒ

æœ¬ç•ªç’°å¢ƒ (Production)
â”œâ”€â”€ æœ¬ç•ªã‚µãƒ¼ãƒãƒ¼ç’°å¢ƒ
â”œâ”€â”€ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç’°å¢ƒ
â””â”€â”€ ãƒ‡ã‚£ã‚¶ã‚¹ã‚¿ãƒªã‚«ãƒãƒªç’°å¢ƒ
```

## 1. æœ¬ç•ªç’°å¢ƒãƒ‡ãƒ—ãƒ­ã‚¤æ‰‹é †

### 1.1 äº‹å‰æº–å‚™

#### ã‚µãƒ¼ãƒãƒ¼è¦ä»¶ç¢ºèª

```bash
# ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶ãƒã‚§ãƒƒã‚¯
docker --version
docker-compose --version
df -h
free -h
nproc
```

#### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š

```bash
# ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«è¨­å®š
sudo ufw allow 80/tcp
sudo ufw allow 443/tcp
sudo ufw allow 22/tcp

# Dockerã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š
sudo usermod -aG docker $USER
sudo systemctl enable docker
sudo systemctl start docker
```

### 1.2 ç’°å¢ƒå¤‰æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ

```bash
# .env.prod ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ
cat > .env.prod << EOF
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š
POSTGRES_PASSWORD=your_secure_password_here
POSTGRES_USER=meatmetrics
POSTGRES_DB=meatmetrics

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
SPRING_PROFILES_ACTIVE=prod
JWT_SECRET=your_jwt_secret_here
API_KEY=your_api_key_here

# å¤–éƒ¨ã‚µãƒ¼ãƒ“ã‚¹è¨­å®š
AWS_ACCESS_KEY_ID=your_aws_key
AWS_SECRET_ACCESS_KEY=your_aws_secret
AWS_REGION=ap-northeast-1

# ç›£è¦–è¨­å®š
LOG_LEVEL=INFO
METRICS_ENABLED=true
EOF

# æ¨©é™è¨­å®š
chmod 600 .env.prod
```

### 1.3 SSL è¨¼æ˜æ›¸ã®æº–å‚™

```bash
# Let's Encryptè¨¼æ˜æ›¸ã®å–å¾—
sudo apt-get install certbot
sudo certbot certonly --standalone -d yourdomain.com

# è¨¼æ˜æ›¸ã®é…ç½®
sudo mkdir -p /etc/nginx/ssl
sudo cp /etc/letsencrypt/live/yourdomain.com/fullchain.pem /etc/nginx/ssl/
sudo cp /etc/letsencrypt/live/yourdomain.com/privkey.pem /etc/nginx/ssl/
sudo chmod 600 /etc/nginx/ssl/*
```

### 1.4 æœ¬ç•ªç’°å¢ƒã®èµ·å‹•

```bash
# 1. ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç§»å‹•
cd infrastructure/docker/prod

# 2. æœ¬ç•ªç’°å¢ƒã®èµ·å‹•
docker compose --env-file .env.prod up -d --build

# 3. èµ·å‹•ç¢ºèª
docker compose ps

# 4. ãƒ­ã‚°ç¢ºèª
docker compose logs -f
```

## 2. ç¶™ç¶šçš„ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ (CD)

### 2.1 GitHub Actions è¨­å®š

```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    branches: [main]
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3

      - name: Deploy to server
        uses: appleboy/ssh-action@v0.1.5
        with:
          host: ${{ secrets.HOST }}
          username: ${{ secrets.USERNAME }}
          key: ${{ secrets.KEY }}
          script: |
            cd /opt/meatmetrics/infrastructure/docker/prod
            git -C ../../.. pull origin main
            docker compose --env-file .env.prod down
            docker compose --env-file .env.prod up -d --build
            docker system prune -f
```

### 2.2 ãƒ‡ãƒ—ãƒ­ã‚¤ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```bash
#!/bin/bash
# deploy.sh

set -e

echo "ğŸš€ ãƒ‡ãƒ—ãƒ­ã‚¤é–‹å§‹: $(date)"

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
source .env.prod

# æœ€æ–°ã‚³ãƒ¼ãƒ‰ã®å–å¾—
git pull origin main

# æ—¢å­˜ã‚³ãƒ³ãƒ†ãƒŠã®åœæ­¢
docker compose down

# ã‚¤ãƒ¡ãƒ¼ã‚¸ã®å†ãƒ“ãƒ«ãƒ‰
docker compose build --no-cache

# æ–°ã‚³ãƒ³ãƒ†ãƒŠã®èµ·å‹•
docker compose up -d

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
echo "â³ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ä¸­..."
sleep 30

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å‹•ä½œç¢ºèª
if curl -f http://localhost/api/health; then
    echo "âœ… ãƒ‡ãƒ—ãƒ­ã‚¤æˆåŠŸ"
else
    echo "âŒ ãƒ‡ãƒ—ãƒ­ã‚¤å¤±æ•— - ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ"
    docker compose down
    docker compose up -d
    exit 1
fi

# å¤ã„ã‚¤ãƒ¡ãƒ¼ã‚¸ã®å‰Šé™¤
docker system prune -f

echo "ğŸ‰ ãƒ‡ãƒ—ãƒ­ã‚¤å®Œäº†: $(date)"
```

## 3. ç›£è¦–ãƒ»ãƒ­ã‚°ç®¡ç†

### 3.1 ãƒ­ã‚°åé›†è¨­å®š

```yaml
# docker-compose.prod.yml ã«è¿½åŠ 
services:
  backend:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  frontend:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  nginx:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
```

### 3.2 ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š

```bash
# /etc/logrotate.d/docker
/var/lib/docker/containers/*/*.log {
    rotate 7
    daily
    compress
    size=1M
    missingok
    delaycompress
    copytruncate
}
```

### 3.3 ç›£è¦–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```bash
#!/bin/bash
# health_check.sh

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯é–¢æ•°
check_service() {
    local service=$1
    local url=$2

    if curl -f -s "$url" > /dev/null; then
        echo "âœ… $service: æ­£å¸¸"
        return 0
    else
        echo "âŒ $service: ç•°å¸¸"
        return 1
    fi
}

# å„ã‚µãƒ¼ãƒ“ã‚¹ã®ãƒã‚§ãƒƒã‚¯
check_service "Frontend" "http://localhost"
check_service "Backend API" "http://localhost/api/health"
check_service "Database" "http://localhost:15432"

# ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯
echo "ğŸ“Š ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡:"
docker stats --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}"
```

## 4. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ»å¾©æ—§

### 4.1 ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—

```bash
#!/bin/bash
# backup_db.sh

BACKUP_DIR="/opt/backups"
DATE=$(date +%Y%m%d_%H%M%S)
DB_NAME="meatmetrics"

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
mkdir -p $BACKUP_DIR

# PostgreSQLãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
docker exec meatmetrics-postgres-prod pg_dump -U meatmetrics $DB_NAME > $BACKUP_DIR/db_backup_$DATE.sql

# åœ§ç¸®
gzip $BACKUP_DIR/db_backup_$DATE.sql

# å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®å‰Šé™¤ï¼ˆ30æ—¥ä»¥ä¸Šå¤ã„ã‚‚ã®ï¼‰
find $BACKUP_DIR -name "db_backup_*.sql.gz" -mtime +30 -delete

echo "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: db_backup_$DATE.sql.gz"
```

### 4.2 ãƒœãƒªãƒ¥ãƒ¼ãƒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—

```bash
#!/bin/bash
# backup_volumes.sh

BACKUP_DIR="/opt/backups/volumes"
DATE=$(date +%Y%m%d_%H%M%S)

mkdir -p $BACKUP_DIR

# PostgreSQLãƒœãƒªãƒ¥ãƒ¼ãƒ ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
docker run --rm -v postgres16_data:/data -v $BACKUP_DIR:/backup alpine tar czf /backup/postgres_data_$DATE.tar.gz -C /data .

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚°ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
docker run --rm -v backend_logs:/data -v $BACKUP_DIR:/backup alpine tar czf /backup/backend_logs_$DATE.tar.gz -C /data .

echo "ãƒœãƒªãƒ¥ãƒ¼ãƒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: $DATE"
```

### 4.3 å¾©æ—§æ‰‹é †

```bash
#!/bin/bash
# restore_db.sh

BACKUP_FILE=$1
DB_NAME="meatmetrics"

if [ -z "$BACKUP_FILE" ]; then
    echo "ä½¿ç”¨æ–¹æ³•: $0 <ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«>"
    exit 1
fi

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å¾©æ—§
docker exec -i meatmetrics-postgres-prod psql -U meatmetrics $DB_NAME < $BACKUP_FILE

echo "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å¾©æ—§å®Œäº†: $BACKUP_FILE"
```

## 5. ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãƒ»è² è·åˆ†æ•£

### 5.1 æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

```yaml
# docker-compose.prod.yml ã«è¿½åŠ 
services:
  backend:
    deploy:
      replicas: 3
      resources:
        limits:
          memory: 1G
          cpus: "0.5"
        reservations:
          memory: 512M
          cpus: "0.25"
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s

  frontend:
    deploy:
      replicas: 2
      resources:
        limits:
          memory: 512M
          cpus: "0.25"
```

### 5.2 ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼è¨­å®š

```nginx
# nginx/nginx.conf (ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¯¾å¿œç‰ˆ)
upstream backend {
    least_conn;  # æœ€å°æ¥ç¶šæ•°æ–¹å¼
    server backend:8080 max_fails=3 fail_timeout=30s;
    server backend:8081 max_fails=3 fail_timeout=30s;
    server backend:8082 max_fails=3 fail_timeout=30s;
}

upstream frontend {
    ip_hash;  # ã‚»ãƒƒã‚·ãƒ§ãƒ³ä¿æŒ
    server frontend:3000 max_fails=3 fail_timeout=30s;
    server frontend:3001 max_fails=3 fail_timeout=30s;
}
```

## 6. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–

### 6.1 ã‚³ãƒ³ãƒ†ãƒŠã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£

```yaml
# docker-compose.prod.yml ã«è¿½åŠ 
services:
  backend:
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp
      - /var/tmp
    user: "1000:1000"

  frontend:
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp
      - /var/tmp
    user: "1000:1000"
```

### 6.2 ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£

```yaml
# docker-compose.prod.yml ã«è¿½åŠ 
networks:
  meatmetrics-network:
    driver: bridge
    internal: true # å¤–éƒ¨ã‹ã‚‰ã®ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ã‚’åˆ¶é™
    ipam:
      config:
        - subnet: 172.20.0.0/16
          gateway: 172.20.0.1
```

## 7. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### 7.1 ã‚­ãƒ£ãƒƒã‚·ãƒ¥æˆ¦ç•¥

```nginx
# nginx/nginx.conf ã«è¿½åŠ 
# é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg)$ {
    expires 1y;
    add_header Cache-Control "public, immutable";
    add_header Vary Accept-Encoding;
}

# APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
location /api/ {
    proxy_cache_valid 200 1m;
    proxy_cache_valid 404 1m;
    add_header X-Cache-Status $upstream_cache_status;
}
```

### 7.2 ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–

```yaml
# docker-compose.prod.yml ã«è¿½åŠ 
services:
  postgres:
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_USER: meatmetrics
      POSTGRES_DB: meatmetrics
      # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®š
      POSTGRES_SHARED_BUFFERS: 256MB
      POSTGRES_EFFECTIVE_CACHE_SIZE: 1GB
      POSTGRES_WORK_MEM: 4MB
      POSTGRES_MAINTENANCE_WORK_MEM: 64MB
```

## 8. éšœå®³å¯¾å¿œãƒ»é‹ç”¨

### 8.1 éšœå®³æ¤œçŸ¥ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```bash
#!/bin/bash
# alert_monitor.sh

# ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š
WEBHOOK_URL="https://hooks.slack.com/services/YOUR/WEBHOOK/URL"

send_alert() {
    local message="$1"
    curl -X POST -H 'Content-type: application/json' \
        --data "{\"text\":\"ğŸš¨ $message\"}" \
        $WEBHOOK_URL
}

# ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯
if ! curl -f -s "http://localhost/api/health" > /dev/null; then
    send_alert "ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ãŒåœæ­¢ã—ã¦ã„ã¾ã™"
fi

if ! curl -f -s "http://localhost" > /dev/null; then
    send_alert "ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ãŒåœæ­¢ã—ã¦ã„ã¾ã™"
fi

# ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡ãƒã‚§ãƒƒã‚¯
MEMORY_USAGE=$(docker stats --no-stream --format "{{.MemPerc}}" | grep -o '[0-9.]*')
if (( $(echo "$MEMORY_USAGE > 80" | bc -l) )); then
    send_alert "ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒ80%ã‚’è¶…ãˆã¦ã„ã¾ã™: ${MEMORY_USAGE}%"
fi
```

### 8.2 è‡ªå‹•å¾©æ—§ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

```bash
#!/bin/bash
# auto_recovery.sh

# è‡ªå‹•å¾©æ—§å‡¦ç†
recover_service() {
    local service=$1

    echo "ğŸ”„ $service ã®è‡ªå‹•å¾©æ—§ã‚’é–‹å§‹..."

    # ã‚³ãƒ³ãƒ†ãƒŠã®å†èµ·å‹•
    docker-compose -f docker-compose.prod.yml restart $service

    # å¾©æ—§ç¢ºèª
    sleep 30
    if docker-compose -f docker-compose.prod.yml ps $service | grep -q "Up"; then
        echo "âœ… $service ã®å¾©æ—§å®Œäº†"
    else
        echo "âŒ $service ã®å¾©æ—§å¤±æ•—"
        # ç®¡ç†è€…ã«é€šçŸ¥
        send_alert "$service ã®è‡ªå‹•å¾©æ—§ã«å¤±æ•—ã—ã¾ã—ãŸ"
    fi
}

# å„ã‚µãƒ¼ãƒ“ã‚¹ã®çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯ã¨å¾©æ—§
for service in backend frontend nginx; do
    if ! docker-compose -f docker-compose.prod.yml ps $service | grep -q "Up"; then
        recover_service $service
    fi
done
```

## 9. é‹ç”¨ç®¡ç†ãƒ„ãƒ¼ãƒ«

### 9.1 ç®¡ç†ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

```yaml
# docker-compose.prod.yml ã«è¿½åŠ 
services:
  portainer:
    image: portainer/portainer-ce:latest
    container_name: meatmetrics-portainer
    ports:
      - "9000:9000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - portainer_data:/data
    networks:
      - meatmetrics-network
    restart: unless-stopped

volumes:
  portainer_data:
```

### 9.2 ãƒ­ã‚°é›†ç´„

```yaml
# docker-compose.prod.yml ã«è¿½åŠ 
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0
    container_name: meatmetrics-elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - meatmetrics-network

  kibana:
    image: docker.elastic.co/kibana/kibana:8.8.0
    container_name: meatmetrics-kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    networks:
      - meatmetrics-network
    depends_on:
      - elasticsearch

volumes:
  elasticsearch_data:
```

---

**æœ€çµ‚æ›´æ–°**: 2025 å¹´ 8 æœˆ 10 æ—¥  
**æ›´æ–°è€…**: é–‹ç™ºãƒãƒ¼ãƒ   
**æ¬¡å›æ›´æ–°äºˆå®š**: ç’°å¢ƒæ§‹ç¯‰å®Œäº†å¾Œ
